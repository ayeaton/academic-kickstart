---
title: K-Means
author: Anna Yeaton
date: '2020-01-05'
slug: k-means
categories: []
tags: ["Clustering"]
subtitle: ''
summary: 'Here we do K-means by hand!'
authors: ["Anna Yeaton"]
lastmod: '2020-01-05T18:42:22-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
---




1. Choose the K number of clusters.
2. Split the data randomly into K groups.  
3. Iterate the following until the cluster assignments stop changing or until the predetermined number of iterations:
    * For each of the K clusters, compute the cluster centroid. The kth cluster centroid is the vector of the p feature means for the observations in the kth cluster. 
    * Assign each observation to the cluster whose centroid is the closest in squared euclidean distance. 


We will work with the Iris data. 

```r
data(iris)
# select the numeric data
iris_data <- iris %>% 
  select(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width))
```

I did a Principal Components Analysis (PCA) using the iris_data, plotted the first two principal components, and colored the points by the iris species. This plot gives us a hint at the structure of the data. 
<img src="/post/2020-01-05-k-means_files/figure-html/unnamed-chunk-2-1.png" width="672" />


## Step 1. Choose K number of clusters: 
I chose K equal to two for simplicity. This means that we are clustering the data into two groups. 

```r
K <- 2
```


## Step 2. Split the data randomly into K groups:
Now I split the data randomly into two groups (because I chose K to equal two).

```r
set.seed(10)
# Randomly assign a number, from 1 to K, to each of the observations. 

# Here I sampled from One or Two (because K equals two), for each data point in iris.
rand_idx <- sample(c("One", "Two"), nrow(iris_data), replace=TRUE, prob=c(0.5, 0.5))
# I add a column to the iris_data called cluster_id with the randomly assigned groups. 
iris_data$cluster_id <- rand_idx
```

On the PCA plot, we see that the two groups are randomly assigned. 
<img src="/post/2020-01-05-k-means_files/figure-html/unnamed-chunk-5-1.png" width="672" />

## Step 3. Iterate the following until the cluster assigments stop changing

1. For each K cluster, compute the cluster centroid. 

2. Assign each observation to the cluster whose centroid is the closest in squared euclidean distance. 

Step 3.1 Compute the cluster centroid for each cluster by taking the mean of every point in each cluster. 

```r
(cluster_centroids <- iris_data %>% 
 group_by(cluster_id) %>% 
  summarise_at(vars(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)), 
               ~mean(., na.rm=TRUE)) %>% 
   column_to_rownames("cluster_id"))
```

```
##     Sepal.Length Sepal.Width Petal.Length Petal.Width
## One     5.857353    3.041176     3.827941    1.248529
## Two     5.831707    3.070732     3.700000    1.158537
```

<img src="/post/2020-01-05-k-means_files/figure-html/unnamed-chunk-7-1.png" width="672" />


Step 3.2 Assign each observation to the cluster whose centroid is the closest in squared euclidean space.

```r
# our squared euclidean distance function 
sq_euclidean_dist <- function(x1, x2) {
  sum((x1 - x2) ^ 2)
}

# apply over the iris_data excluding the cluster_id
# calculate the squared euclidean distance between the row and the cluster 
# centroid of cluster "One"
dist_k1 <- apply(iris_data %>% select(-cluster_id), 
                 1, # rowwise
                 function(x){ 
                   sq_euclidean_dist(x, 
                                     as.numeric(cluster_centroids["One",]))
                   })

dist_k2 <- apply(iris_data %>% select(-cluster_id), 
                 1, # rowwise
                 function(x){ 
                   sq_euclidean_dist(x, 
                                     as.numeric(cluster_centroids["Two",]))
                   })
```



```r
distances <- data.frame(Cluster_one = dist_k1,
                        Cluster_two = dist_k2)
```

This distances data frame holds the distances of each data point in iris_data to the two cluster 
centroids. Distances has 150 rows and 2 columns. 


```r
head(distances)
```

```
##   Cluster_one Cluster_two
## 1    7.778415    6.928459
## 2    7.912532    7.081874
## 3    8.854591    7.976264
## 4    8.103121    7.276752
## 5    8.041650    7.180654
## 6    6.194885    5.449435
```


So now we have to assign each point to the closest centroid. 

```r
# assign each observation to the closest cluster by
# iterating over the rows of the dataframe distances and finding which column 
# is the minimum value in that row. 
idx <- apply(distances, 1, function(x){ which.min(x)})
idx <- ifelse(idx == 1, "One", "Two")

iris_data$cluster_id <- idx
```


<img src="/post/2020-01-05-k-means_files/figure-html/unnamed-chunk-12-1.png" width="672" />


Now we iterate over Step 3. We will only iterate for 3 times. 


```r
# Here I sampled from One or Two (because K equals two), for each data point in iris.
rand_idx <- sample(c("One", "Two"), nrow(iris_data), replace=TRUE, prob=c(0.5, 0.5))
# I add a column to the iris_data called cluster_id with the randomly assigned groups. 
iris_data$cluster_id <- rand_idx

save_pcs <- pcs[,c("PC1", "PC2")]
save_pcs$cluster <- rand_idx
save_pcs$id <- 1

for( i in 2:5){
  
  dist_k1 <- apply(iris_data %>% select(-cluster_id), 
                   1, # rowwise
                   function(x){ 
                     sq_euclidean_dist(x, 
                                       as.numeric(cluster_centroids["One",]))
                     })
  
  dist_k2 <- apply(iris_data %>% select(-cluster_id), 
                   1, # rowwise
                   function(x){ 
                     sq_euclidean_dist(x, 
                                       as.numeric(cluster_centroids["Two",]))
                     })
  
  distances <- data.frame(Cluster_one = dist_k1,
                          Cluster_two = dist_k2)
  
  idx <- apply(distances, 1, function(x){ which.min(x)})
  idx <- ifelse(idx == 1, "One", "Two")
  
  iris_data$cluster_id <- idx
  
  test <- pcs[,c("PC1", "PC2")]
  test$cluster <- idx
  test$id <- i
  
  save_pcs <- rbind(save_pcs, test)
  
  (cluster_centroids <- iris_data %>% 
     group_by(cluster_id) %>% 
     summarise_at(vars(c(Sepal.Length, Sepal.Width, Petal.Length, Petal.Width)), 
               ~mean(., na.rm=TRUE)) %>% 
     column_to_rownames("cluster_id"))
  
  centroid_points <- as.data.frame(scale(as.matrix(cluster_centroids),
                                         pca$center, pca$scale) %*% as.matrix(pca$rotation[, c("PC1", "PC2")]))
  

}
```



```r
# save_pcs$group <- seq_len(nrow(save_pcs))
# (current_clust <- ggplot(save_pcs, aes(PC1, PC2, group =group, color = cluster)) + 
#   geom_point() + 
#   theme_bw()  + 
#   transition_states(id, transition_length = 3, state_length = 1))
```

